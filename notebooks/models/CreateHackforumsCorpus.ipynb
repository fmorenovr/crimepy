{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>CVE</th>\n",
       "      <th>IdPost</th>\n",
       "      <th>Time</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Content</th>\n",
       "      <th>obs</th>\n",
       "      <th>Tags0</th>\n",
       "      <th>Tags1</th>\n",
       "      <th>Tags2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>cve-2012-0500</td>\n",
       "      <td>7345.0</td>\n",
       "      <td>2012-03-06 00:28:00-03:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Binary Analysis of Oracle Java CVE: 2012-0500 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>weaponization</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1263.0</td>\n",
       "      <td>cve-2013-0431</td>\n",
       "      <td>32622237.0</td>\n",
       "      <td>2013-05-13 22:24:00-03:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ok I've made threads about this before and non...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>exploitation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>cve-2017-0199</td>\n",
       "      <td>56090050.0</td>\n",
       "      <td>2017-10-18 08:34:00-02:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>***CITING***[https://hackforums.net/showthread...</td>\n",
       "      <td>Trillium</td>\n",
       "      <td>exploitation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1617.0</td>\n",
       "      <td>cve-2015-0313</td>\n",
       "      <td>45426930.0</td>\n",
       "      <td>2015-03-27 00:01:00-03:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Has CVE means not 0day\\nIf you're talking abou...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>weaponization</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>526.0</td>\n",
       "      <td>cve-2016-5195</td>\n",
       "      <td>53854632.0</td>\n",
       "      <td>2017-01-19 02:07:00-02:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>How To Get Root Access to Any Server\\n\\nHello ...</td>\n",
       "      <td>tutorial</td>\n",
       "      <td>PoC</td>\n",
       "      <td>exploitation</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Unnamed: 0  Unnamed: 0.1            CVE      IdPost  \\\n",
       "0      0           0        1550.0  cve-2012-0500      7345.0   \n",
       "1      2           2        1263.0  cve-2013-0431  32622237.0   \n",
       "2      4           4        1223.0  cve-2017-0199  56090050.0   \n",
       "3      5           5        1617.0  cve-2015-0313  45426930.0   \n",
       "4      6           6         526.0  cve-2016-5195  53854632.0   \n",
       "\n",
       "                        Time  Likes  \\\n",
       "0  2012-03-06 00:28:00-03:00    NaN   \n",
       "1  2013-05-13 22:24:00-03:00    NaN   \n",
       "2  2017-10-18 08:34:00-02:00    NaN   \n",
       "3  2015-03-27 00:01:00-03:00    NaN   \n",
       "4  2017-01-19 02:07:00-02:00    NaN   \n",
       "\n",
       "                                             Content       obs          Tags0  \\\n",
       "0  Binary Analysis of Oracle Java CVE: 2012-0500 ...       NaN  weaponization   \n",
       "1  Ok I've made threads about this before and non...       NaN   exploitation   \n",
       "2  ***CITING***[https://hackforums.net/showthread...  Trillium   exploitation   \n",
       "3  Has CVE means not 0day\\nIf you're talking abou...       NaN  weaponization   \n",
       "4  How To Get Root Access to Any Server\\n\\nHello ...  tutorial            PoC   \n",
       "\n",
       "          Tags1 Tags2  \n",
       "0           NaN   NaN  \n",
       "1           NaN   NaN  \n",
       "2           NaN   NaN  \n",
       "3           NaN   NaN  \n",
       "4  exploitation   NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"../crimeBB/crimebb_preprocessed.csv\")\n",
    "df.dropna(subset=['Tags0'], inplace=True) # drop rows without labels\n",
    "df.CVE = df.CVE.str.lower()\n",
    "df = df[~df.Tags0.isin(['russian', '\\\\', 'others', 'doubt', 'error', 'market'])]\n",
    "df.reset_index(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk:  1\n",
      "took:  751.7687385082245\n",
      "chunk:  2\n",
      "took:  745.759961605072\n",
      "chunk:  3\n",
      "took:  744.8197755813599\n",
      "chunk:  4\n",
      "took:  761.7826633453369\n",
      "chunk:  5\n",
      "took:  758.2635855674744\n",
      "chunk:  6\n",
      "took:  772.2487435340881\n",
      "chunk:  7\n",
      "took:  644.3198282718658\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "import multiprocessing\n",
    "import gc\n",
    "\n",
    "def filter_stopwords(words):\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    wordsFiltered = []\n",
    "    for w in words:\n",
    "        if w not in stopWords:\n",
    "            wordsFiltered.append(w)\n",
    "    return wordsFiltered\n",
    "\n",
    "def removePunctuation(text):\n",
    "    return text.translate(str.maketrans(punctuation, \" \"*len(punctuation)))\n",
    "\n",
    "def stem(words):\n",
    "    return [ps.stem(word) for word in words]\n",
    "\n",
    "def writeLine(line):\n",
    "    f.write(line + \"\\n\")\n",
    "    \n",
    "def preprocessLine(line):\n",
    "    line = removePunctuation(line)\n",
    "    line = list(filter(lambda x: x not in stopWords, word_tokenize(line)))\n",
    "    line = stem(line)\n",
    "    line = \" \".join(line)\n",
    "    writeLine(line)\n",
    "\n",
    "stopWords = set(stopwords.words('english'))\n",
    "ps = nltk.stem.PorterStemmer()\n",
    "\n",
    "files = ['hackforums_corpus.csv']\n",
    "punctuation = string.punctuation\n",
    "i = 1\n",
    "with open(\"hackforums_corpus.txt\", \"w\") as f:\n",
    "    for file in files:\n",
    "        chunks = pd.read_csv(file, names=['Content'], chunksize=1000000)\n",
    "        for chunk in chunks:\n",
    "            start = time.time()\n",
    "            print(\"chunk: \", i)\n",
    "            i += 1\n",
    "            chunk['Content'] = chunk['Content'].astype(str)\n",
    "            chunk.Content.str.lower().map(preprocessLine)\n",
    "            del chunk\n",
    "            gc.collect()\n",
    "            print(\"took: \", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       None\n",
       "1       None\n",
       "2       None\n",
       "3       None\n",
       "4       None\n",
       "5       None\n",
       "6       None\n",
       "7       None\n",
       "8       None\n",
       "9       None\n",
       "10      None\n",
       "11      None\n",
       "12      None\n",
       "13      None\n",
       "14      None\n",
       "15      None\n",
       "16      None\n",
       "17      None\n",
       "18      None\n",
       "19      None\n",
       "20      None\n",
       "21      None\n",
       "22      None\n",
       "23      None\n",
       "24      None\n",
       "25      None\n",
       "26      None\n",
       "27      None\n",
       "28      None\n",
       "29      None\n",
       "        ... \n",
       "2146    None\n",
       "2147    None\n",
       "2148    None\n",
       "2149    None\n",
       "2150    None\n",
       "2151    None\n",
       "2152    None\n",
       "2153    None\n",
       "2154    None\n",
       "2155    None\n",
       "2156    None\n",
       "2157    None\n",
       "2158    None\n",
       "2159    None\n",
       "2160    None\n",
       "2161    None\n",
       "2162    None\n",
       "2163    None\n",
       "2164    None\n",
       "2165    None\n",
       "2166    None\n",
       "2167    None\n",
       "2168    None\n",
       "2169    None\n",
       "2170    None\n",
       "2171    None\n",
       "2172    None\n",
       "2173    None\n",
       "2174    None\n",
       "2175    None\n",
       "Name: Content, Length: 2176, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"hackforums_corpus.txt\", \"a\")\n",
    "df.Content = df.Content.astype(str)\n",
    "df.Content.str.lower().map(preprocessLine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"hackforums_corpus\"\n",
    "model = Doc2Vec(corpus_file=fname, vector_size=50, min_count=2, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leu corpus?\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "You can't pass a generator as the documents argument. Try a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-bd11585b90c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# corpus = list(read_corpus(fname))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"leu corpus?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDoc2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, documents, corpus_file, dm_mean, dm, dbow_words, dm_concat, dm_tag_count, docvecs, docvecs_mapfile, comment, trim_rule, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    612\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You must pass string as the corpus_file argument.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGeneratorType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You can't pass a generator as the documents argument. Try a sequence.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m             self.train(\n",
      "\u001b[0;31mTypeError\u001b[0m: You can't pass a generator as the documents argument. Try a sequence."
     ]
    }
   ],
   "source": [
    "import smart_open\n",
    "import gensim\n",
    "fname = \"hackforums_corpus\"\n",
    "\n",
    "def read_corpus(fname, tokens_only=False):\n",
    "    with smart_open.open(fname, encoding=\"iso-8859-1\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            tokens = gensim.utils.simple_preprocess(line)\n",
    "            if tokens_only:\n",
    "                yield tokens\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
    "\n",
    "# corpus = list(read_corpus(fname))\n",
    "model = Doc2Vec(read_corpus(fname), vector_size=300, min_count=2)\n",
    "model.build_vocab(corpus)\n",
    "model.train(corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PoC', 'exploitation', 'weaponization'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl = LabelEncoder()\n",
    "df.Tags0 = lbl.fit_transform(df.Tags0.astype(str))\n",
    "lbl.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import RegexpTokenizer\n",
    "#tokenize\n",
    "\n",
    "tk = RegexpTokenizer(r\"[a-zA-Z]+\")\n",
    "df['ContentTokenized'] = pd.Series(['']*len(df))\n",
    "df['Content'] = df['Content'].astype(str).str.lower()\n",
    "for i in range(len(df)):\n",
    "    words = tk.tokenize(df.at[i, 'Content'])\n",
    "#     words = [word for word in nltk.word_tokenize(df.at[i, 'Content']) if word.isalnum()]\n",
    "    df.at[i, 'ContentTokenized'] = filter_stopwords(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Doc2Vec in whole dataset and evaluating its perfomance against the subset of posts citing CVEs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
